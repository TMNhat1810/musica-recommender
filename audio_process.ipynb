{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\capstone\\misc\\RecommenderSystem\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import cv2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, Distance, VectorParams, CollectionConfig\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = QdrantClient('localhost', port=6333)\n",
    "\n",
    "collection_name = \"video_features\"\n",
    "if not qdrant.collection_exists(collection_name):\n",
    "   qdrant.create_collection(\n",
    "      collection_name=collection_name,\n",
    "      vectors_config={\n",
    "        \"title_vector\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "        \"image_vector\": VectorParams(size=512, distance=Distance.COSINE),\n",
    "        \"audio_vector\": VectorParams(size=128, distance=Distance.COSINE),\n",
    "    }\n",
    "   )\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "text_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text embeddings (e.g., using filename as text)\n",
    "def extract_text_embedding(text):\n",
    "    \"\"\"Generate text vector using Sentence Transformers\"\"\"\n",
    "    return text_model.encode(text).tolist()\n",
    "\n",
    "# Function to extract video frame embeddings\n",
    "def extract_video_embedding(video_path, num_frames=5):\n",
    "    \"\"\"Extracts frames from a video and computes an average embedding\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    for i in np.linspace(0, frame_count - 1, num_frames).astype(int):  # Sample evenly spaced frames\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # Convert to PIL image and preprocess\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Encode using CLIP\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(image_tensor).cpu().numpy().flatten()\n",
    "        \n",
    "        frames.append(image_features)\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    if frames:\n",
    "        return np.mean(frames, axis=0).tolist()  # Average frame embeddings\n",
    "    else:\n",
    "        return [0] * 512  # Default vector if no frames extracted\n",
    "\n",
    "# Function to extract audio embeddings\n",
    "def extract_audio_embedding(video_path):\n",
    "    \"\"\"Extracts audio from video and computes an MFCC-based embedding\"\"\"\n",
    "    y, sr = librosa.load(video_path, sr=16000, duration=10)  # Load first 10 seconds\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=128)\n",
    "    audio_vector = np.mean(mfcc, axis=1)  # Take mean across time\n",
    "\n",
    "    return audio_vector.tolist()\n",
    "\n",
    "# Function to process and store in Qdrant\n",
    "def process_video(video_path):\n",
    "    \"\"\"Extract features and store them in Qdrant\"\"\"\n",
    "    video_id = os.path.basename(video_path).split(\".\")[0]  # Use filename as ID\n",
    "    video_title = os.path.basename(video_path)  # Use filename as title\n",
    "\n",
    "    # Extract features\n",
    "    title_vector = extract_text_embedding(video_title)\n",
    "    video_vector = extract_video_embedding(video_path)\n",
    "    audio_vector = extract_audio_embedding(video_path)\n",
    "\n",
    "    # Store in Qdrant\n",
    "    qdrant.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            PointStruct(\n",
    "                id=int(hash(video_id) % 1_000_000),  # Unique but simple ID\n",
    "                vector={\n",
    "                    \"title_vector\": title_vector,\n",
    "                    \"video_vector\": video_vector,\n",
    "                    \"audio_vector\": audio_vector\n",
    "                },\n",
    "                payload={\"title\": video_title}  # Store title as metadata\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Processed and stored: {video_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\video\\\\As It Was (Harry Styles) - NELL X Sungha Jung [O9-CQndjtEQ].mp4',\n",
       " 'data\\\\video\\\\Classical Gasüî• [cx6Nva2yUjk].mp4',\n",
       " \"data\\\\video\\\\Don't Stop Me Now (Queen) - Sungha Jung [pqQf1uD5m90].mp4\",\n",
       " 'data\\\\video\\\\Flaming (With Kotaro Oshio) - Sungha Jung (Official Music Video) [tJIkyeTqExE].mp4',\n",
       " 'data\\\\video\\\\Seventh #9 - Sungha Jung [i3-mzP_KYVc].mp4',\n",
       " 'data\\\\video\\\\Sukidakara (Yuika) [-Iz-dnVCfto].mp4']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_files = [os.path.join('data', 'video', filename) for filename in os.listdir('data/video')]\n",
    "video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhn\\AppData\\Local\\Temp\\ipykernel_14648\\1368872385.py:44: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(video_path, sr=16000, duration=10)  # Load first 10 seconds\n",
      "d:\\code\\capstone\\misc\\RecommenderSystem\\.venv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed and stored: As It Was (Harry Styles) - NELL X Sungha Jung [O9-CQndjtEQ].mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhn\\AppData\\Local\\Temp\\ipykernel_14648\\1368872385.py:44: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(video_path, sr=16000, duration=10)  # Load first 10 seconds\n",
      "d:\\code\\capstone\\misc\\RecommenderSystem\\.venv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed and stored: Classical Gasüî• [cx6Nva2yUjk].mp4\n",
      "‚úÖ Processed and stored: Don't Stop Me Now (Queen) - Sungha Jung [pqQf1uD5m90].mp4\n",
      "‚úÖ Processed and stored: Flaming (With Kotaro Oshio) - Sungha Jung (Official Music Video) [tJIkyeTqExE].mp4\n",
      "‚úÖ Processed and stored: Seventh #9 - Sungha Jung [i3-mzP_KYVc].mp4\n",
      "‚úÖ Processed and stored: Sukidakara (Yuika) [-Iz-dnVCfto].mp4\n"
     ]
    }
   ],
   "source": [
    "for video_file in video_files:\n",
    "    process_video(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_all_vectors():\n",
    "    result = qdrant.scroll(\n",
    "        collection_name=collection_name,\n",
    "        limit=100,  # Adjust to fetch more points\n",
    "        with_vectors=True,   # Include stored vectors\n",
    "        with_payload=True    # Include metadata (e.g., title)\n",
    "    )\n",
    "    \n",
    "    for point in result[0]:  # Qdrant returns (data, next_offset)\n",
    "        print(f\"üÜî ID: {point.id}\")\n",
    "        print(f\"üìå Title: {point.payload.get('title', 'No Title')}\")\n",
    "        print(f\"üñºÔ∏è Title Vector (First 5): {point.vector.get('title_vector')[:5]}...\")\n",
    "        print(f\"üìπ Video Vector (First 5): {point.vector.get('video_vector')[:5]}...\")\n",
    "        print(f\"üéµ Audio Vector (First 5): {point.vector.get('audio_vector')[:5]}...\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "\n",
    "fetch_all_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Searching for videos similar to Video ID 963694\n",
      "\n",
      "üÜî Video ID: 760266\n",
      "üîç Similarity Score: 0.9537\n",
      "üìå Title: Sukidakara (Yuika) [-Iz-dnVCfto].mp4\n",
      "--------------------------------------------------\n",
      "üÜî Video ID: 171697\n",
      "üîç Similarity Score: 0.9514\n",
      "üìå Title: Seventh #9 - Sungha Jung [i3-mzP_KYVc].mp4\n",
      "--------------------------------------------------\n",
      "üÜî Video ID: 284614\n",
      "üîç Similarity Score: 0.9383\n",
      "üìå Title: Don't Stop Me Now (Queen) - Sungha Jung [pqQf1uD5m90].mp4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhn\\AppData\\Local\\Temp\\ipykernel_18072\\3808235069.py:11: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant.search(\n"
     ]
    }
   ],
   "source": [
    "def find_similar_videos(video_id, top_k=5):\n",
    "    # Fetch the selected video's vector\n",
    "    response = qdrant.retrieve(collection_name, [video_id], with_vectors=True)\n",
    "    if not response:\n",
    "        print(\"‚ö†Ô∏è Video not found in the collection!\")\n",
    "        return\n",
    "    \n",
    "    video_vector = response[0].vector[\"video_vector\"]  # Extract video vector\n",
    "\n",
    "    # Search for top-k similar videos\n",
    "    search_results = qdrant.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=(\"video_vector\", video_vector),\n",
    "        limit=top_k + 1,  # +1 to exclude itself\n",
    "    )\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"üéØ Searching for videos similar to Video ID {video_id}\\n\")\n",
    "    for result in search_results:\n",
    "        if result.id == video_id:  # Skip the query video itself\n",
    "            continue\n",
    "        print(f\"üÜî Video ID: {result.id}\")\n",
    "        print(f\"üîç Similarity Score: {result.score:.4f}\")\n",
    "        print(f\"üìå Title: {result.payload.get('title', 'No Title')}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "find_similar_videos(video_id=963694, top_k=3)  # Replace with a real video ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
